{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from load_data import create_eeg_data\n",
    "\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "import pickle\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import read_inverse_operator, compute_source_psd\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path\n",
    "path = 'D:/NISE_project_data/eeg-motor-movementimagery-dataset-1.0.0/files/'\n",
    "#path = '/home/matthijspals/physionet.org/files/eegmmidb/1.0.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(epochs,trial,frequencies=np.arange(8, 30, 1),n_cycles=10,average=False,tmin=0.25,tmax=4,verbose=True, n_ch=3):\n",
    "    power = mne.time_frequency.tfr_morlet(epochs ,n_cycles=n_cycles,\n",
    "                                      freqs=frequencies, average=False, return_itc=False,verbose=False, use_fft=True)\n",
    "    times=np.linspace(start=tmin,stop=tmax,num=epochs.get_data().shape[2])\n",
    "    if verbose:\n",
    "        #plt.figure(figsize=(15, 10))\n",
    "        #plt.subplot(1,3,1)\n",
    "        #plt.pcolormesh(times,frequencies,power.data[trial,0,:,:])\n",
    "        #plt.subplot(1,3,2)\n",
    "        #plt.pcolormesh(times,frequencies,power.data[trial,1,:,:])\n",
    "        #plt.subplot(1,3,3)\n",
    "        #plt.pcolormesh(times,frequencies,power.data[trial,2,:,:])\n",
    "        img=plt.imshow(power.data[trial,0:n_ch,:,:].reshape(n_ch*frequencies.shape[0],601),aspect=\"auto\",origin=\"lower\")\n",
    "    \n",
    "    return power.data[trial,0:n_ch,:,:].reshape(n_ch*frequencies.shape[0],601),img #(trials,channels,spectogram1,spectogram2)\n",
    "\n",
    "def rgba2rgb( rgba, background=(255,255,255) ):\n",
    "    row, col, ch = rgba.shape\n",
    "\n",
    "    if ch == 3:\n",
    "        return rgba\n",
    "\n",
    "    assert ch == 4, 'RGBA image has 4 channels.'\n",
    "\n",
    "    rgb = np.zeros( (row, col, 3), dtype='float32' )\n",
    "    r, g, b, a = rgba[:,:,0], rgba[:,:,1], rgba[:,:,2], rgba[:,:,3]\n",
    "\n",
    "    a = np.asarray( a, dtype='float32' ) / 255.0\n",
    "\n",
    "    R, G, B = background\n",
    "\n",
    "    rgb[:,:,0] = r * a + (1.0 - a) * R\n",
    "    rgb[:,:,1] = g * a + (1.0 - a) * G\n",
    "    rgb[:,:,2] = b * a + (1.0 - a) * B\n",
    "\n",
    "    return np.asarray( rgb, dtype='uint8' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participants = [1, 2, 3, 6, 7, 12, 14, 15, 18, 20, 21, 22, 29, 30, 31, 32, 33, 36, 37, 40]\n",
    "n_ch = 3\n",
    "participants =[1]\n",
    "tmax = 4\n",
    "tmin = -0.25\n",
    "fs = 160.\n",
    "trials=21\n",
    "samples = int((tmax+tmin)*fs+1)\n",
    "data = np.zeros((0,samples,n_ch))\n",
    "labels = np.zeros(0)\n",
    "lfreq, hfreq= 8, 30\n",
    "freq_spec =  np.logspace(*np.log10([lfreq, hfreq]), num=110)\n",
    "part_idx=0\n",
    "n_cycles = freq_spec/2\n",
    "im_chan=4\n",
    "for part in participants:\n",
    "\n",
    "    #load and filter data\n",
    "    eeg_data = create_eeg_data(path, part = part, task = [0,1,0,1],baseline=True, filt=[lfreq,hfreq])\n",
    "    epochs2 = eeg_data['t2'][0].all_sessions().copy()\n",
    "    epochs4 = eeg_data['t4'][0].all_sessions().copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    sampl = np.random.randint(low=0, high=eeg_data[\"cl_eyes\"][0].get_data().shape[1]-samples, size=(trials,), dtype='l')\n",
    "    events_array = np.zeros([trials,samples,64])\n",
    "\n",
    "    raw0 = eeg_data['cl_eyes'][0].copy()\n",
    "    count = 0\n",
    "    events=[]\n",
    "    for i in range(trials):\n",
    "        events_array[i,:,:]=raw0.get_data()[:,sampl[count]:sampl[count]+samples].T\n",
    "\n",
    "        count = count+1\n",
    "    labels0 = np.zeros([trials,])\n",
    "\n",
    "    new_baseline_raw=mne.io.RawArray(events_array.reshape([64,trials*samples]),epochs2.info,verbose=False)\n",
    "    onsets=np.arange(0,new_baseline_raw.get_data().shape[1]/fs,samples/fs)\n",
    "    duration = np.ones([trials,])*(samples/fs)\n",
    "    description = []\n",
    "    for i in range(trials):\n",
    "        description.append(\"T0\")\n",
    "\n",
    "    annot_base= mne.Annotations(onset=onsets,duration=duration,description=description)\n",
    "    new_baseline_raw = new_baseline_raw.copy().set_annotations(annot_base)\n",
    "    epochs0 = mne.EpochsArray(events_array.transpose([0,2,1]), epochs2.info, events=mne.events_from_annotations(new_baseline_raw,\n",
    "                                    event_id={\"T0\":0})[0], tmin=0.25, event_id=None, reject=None, flat=None, reject_tmin=None,\n",
    "                                    reject_tmax=None, baseline=None, proj=True, on_missing='raise', metadata=None, \n",
    "                                      selection=None, verbose=None)\n",
    "    epochs0.info[\"highpass\"]=lfreq\n",
    "    epochs0.info[\"lowpass\"]=hfreq\n",
    "\n",
    "\n",
    "    epochs_train0 = epochs0.copy().crop(tmin=-tmin, tmax=tmax)\n",
    "    ica = ICA(n_components=64, random_state=97)\n",
    "    ica.fit(epochs_train0)\n",
    "    ica.exclude = []\n",
    "    # find which ICs match the EOG pattern\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(epochs_train0,ch_name='Fpz')\n",
    "    ica.exclude = eog_indices\n",
    "    #aply ICA\n",
    "    ica.apply(epochs0)\n",
    "    epochs_train0 = epochs0.copy().crop(tmin=-tmin, tmax=tmax).pick_channels([\"C3\",\"Cz\",\"C4\"])\n",
    "    \n",
    "    \n",
    "    spec_data_train0 = np.zeros([len(participants),trials,n_ch*freq_spec.shape[0],samples])\n",
    "    img_data_train0 = np.zeros([len(participants),trials,n_ch*freq_spec.shape[0],samples,im_chan]) \n",
    "    for i in range(trials):\n",
    "        spec_data_train0[part_idx,i,:,:],img0=create_spectrogram(epochs_train0,i,frequencies=freq_spec,n_cycles=n_cycles,verbose=True)\n",
    "        img_data_train0[part_idx,i,:,:,:]= img0.cmap(img0.norm(img0.get_array()))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #crop\n",
    "    epochs_train2 = epochs2.copy().crop(tmin=-tmin, tmax=tmax)\n",
    "    \n",
    "    #ICA epochs2\n",
    "    ica = ICA(n_components=64, random_state=97)\n",
    "    ica.fit(epochs_train2)\n",
    "    ica.exclude = []\n",
    "    # find which ICs match the EOG pattern\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(epochs_train2,ch_name='Fpz')\n",
    "    ica.exclude = eog_indices\n",
    "    #aply ICA\n",
    "    ica.apply(epochs2)\n",
    "    \n",
    "    #ICA applied\n",
    "    epochs_train2 = epochs2.copy().crop(tmin=-tmin, tmax=tmax).pick_channels([\"C3\",\"Cz\",\"C4\"])\n",
    "    \n",
    "    spec_data_train2 = np.zeros([len(participants),trials*2,n_ch*freq_spec.shape[0],samples]) \n",
    "    img_data_train2 = np.zeros([len(participants),trials*2,n_ch*freq_spec.shape[0],samples,im_chan]) \n",
    "    for i in range(trials*2):\n",
    "            spec_data_train2[part_idx,i,:,:],img2=create_spectrogram(epochs_train2,i,frequencies=freq_spec,n_cycles=n_cycles,verbose=True)\n",
    "            img_data_train2[part_idx,i,:,:,:]= img2.cmap(img2.norm(img2.get_array()))\n",
    "    labels2 = epochs2.events[:, -1] - 1\n",
    "    epochs_data_train2 = epochs_train2.get_data().transpose([0,2,1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #crop\n",
    "    epochs_train4 = epochs4.copy().crop(tmin=-tmin, tmax=tmax)\n",
    "    \n",
    "    #ICA preprocessing\n",
    "    ica = ICA(n_components=64, random_state=97)\n",
    "    ica.fit(epochs_train4)\n",
    "    ica.exclude = []\n",
    "    # find which ICs match the EOG pattern\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(epochs_train4,ch_name='Fpz')\n",
    "    ica.exclude = eog_indices\n",
    "    #aply ICA\n",
    "    ica.apply(epochs4)\n",
    "    \n",
    "    #ICA applied\n",
    "    epochs_train4 = epochs4.copy().crop(tmin=-tmin, tmax=tmax).pick_channels([\"C3\",\"Cz\",\"C4\"])\n",
    "    \n",
    "    spec_data_train4 = np.zeros([len(participants),trials*2,n_ch*freq_spec.shape[0],samples])\n",
    "    img_data_train4 = np.zeros([len(participants),trials*2,n_ch*freq_spec.shape[0],samples,im_chan])\n",
    "    for i in range(trials*2):\n",
    "            spec_data_train4[part_idx,i,:,:],img4=create_spectrogram(epochs_train4,i,frequencies=freq_spec,n_cycles=n_cycles,verbose=True)\n",
    "            img_data_train4[part_idx,i,:,:,:]= img4.cmap(img4.norm(img4.get_array()))\n",
    "            \n",
    "    labels4 = epochs4.events[:, -1] +1\n",
    "    epochs_data_train4 = epochs_train4.get_data().transpose([0,2,1])\n",
    "\n",
    "    #concatenate to bigg file\n",
    "    labels240 = np.concatenate((labels2, labels4,labels0))\n",
    "    #data24 = np.concatenate((epochs_data_train2, epochs_data_train4, epochs_data_train0),axis=0)\n",
    "    spec240 = np.concatenate((spec_data_train2,spec_data_train4,spec_data_train0),axis=1)\n",
    "    img240 = np.concatenate((img_data_train2,img_data_train4,img_data_train0),axis=1)\n",
    "    #data = np.concatenate((data, data24))\n",
    "    part_idx = part_idx+1\n",
    "    with open('data.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    with open('labels.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(labels, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE ONLY TASK 2 FOR NOW\n",
    "#------------------\n",
    "\n",
    "#img240 = img_data_train2.squeeze()[:,:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#IMAGE COMPRESSION AND NORMALIZATION\n",
    "\n",
    "#for i in range(np.shape(img240)[0]):\n",
    "#    for freq in range(np.shape(img240)[1]):\n",
    "#            img240[i, freq] #-= np.mean(img240[i, freq])\n",
    "#            img240[i, freq] /= np.var(img240[i, freq])\n",
    "            #img240[i, freq] -= np.min(img240[i, freq])\n",
    "\n",
    "img_comp = (np.zeros((np.shape(img240)[0],66,66, 3)))\n",
    "for i in range(np.shape(img240)[0]):\n",
    "    img_comp[i] =  cv2.resize(img240[i], dsize=(66, 66), interpolation=cv2.INTER_CUBIC)\n",
    "#img_comp -= np.min(img_comp)\n",
    "img_comp /=np.max(img_comp)\n",
    "#img_comp = np.expand_dims(img_comp, axis = 3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_old = img240\n",
    "img240 = img240.squeeze()[:,:,:,:3]\n",
    "img_comp = (np.zeros((np.shape(img240)[0],32,32, 3)))\n",
    "for i in range(np.shape(img240)[0]):\n",
    "    img_comp[i] =  cv2.resize(img240[i], dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "img_comp -= np.min(img_comp)\n",
    "img_comp /=np.max(img_comp)\n",
    "img240 = img_comp\n",
    "#img_comp = np.expand_dims(img_comp, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img240[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(img240.squeeze(), labels240):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = img240.squeeze()[train_index,:,:,:3], img240.squeeze()[test_index,:,:,:3]\n",
    "    y_train, y_test = labels240[train_index], labels240[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE HOT ENCODING\n",
    "from keras.utils import to_categorical\n",
    "y_train_OH = to_categorical(y_train)\n",
    "y_test_OH = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(img240.squeeze()[:,:,:,0:3], labels240, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez(\"db/x_norm\", X_train[:10], allow_pickle=True)\n",
    "#np.savez_compressed(os.path.join(path_wd, 'x_norm'), x_train[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train[::40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_OH[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_OH[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grey = np.zeros((len(X_train),32,32))\n",
    "for i in range(len(X_train)):\n",
    "    X_grey[i]=cv2.cvtColor(np.float32(X_train[i]), cv2.COLOR_BGR2GRAY)\n",
    "X_train = X_grey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grey = np.zeros((len(X_test),32,32))\n",
    "for i in range(len(X_test)):\n",
    "    X_grey[i]=cv2.cvtColor(np.float32(X_test[i]), cv2.COLOR_BGR2GRAY)\n",
    "X_test= X_grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[0], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test, axis = 3)\n",
    "X_train = np.expand_dims(X_train, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savez_compressed(\"x_train\", X_train)\n",
    "np.savez_compressed(\"x_test\", X_test)\n",
    "np.savez_compressed(\"x_norm\", X_train[::20])\n",
    "np.savez_compressed(\"y_train\", y_train_OH)\n",
    "np.savez_compressed(\"y_test\", y_test_OH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import Sequential, InputLayer\n",
    "#from keras.layers import Dense, Activation, Flatten\n",
    "#from keras.layers import BatchNormalization, Dropout, Conv2D, MaxPooling2D\n",
    "#from tensorflow import keras\n",
    "\n",
    "#from tensorflow.keras import Sequential, Input\n",
    "#from tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, \\\n",
    "    Dropout\n",
    "\n",
    "\n",
    "input_shape = X_test[0].shape\n",
    "input_layer = Input(input_shape)\n",
    "\n",
    "layer = Conv2D(filters=16,\n",
    "               kernel_size=(5, 5),\n",
    "               strides=(2, 2),\n",
    "               activation='relu',\n",
    "               use_bias=False)(input_layer)\n",
    "\n",
    "layer = Conv2D(filters=32,\n",
    "               kernel_size=(3, 3),\n",
    "               activation='relu',\n",
    "               use_bias=False)(layer)\n",
    "#layer = AveragePooling2D()(layer)\n",
    "layer = Conv2D(filters=8,\n",
    "               kernel_size=(3, 3),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               use_bias=False)(layer)\n",
    "\n",
    "layer = Flatten()(layer)\n",
    "layer = Dropout(0.01)(layer)\n",
    "layer = Dense(units=5,\n",
    "              activation='softmax')(layer)\n",
    "\n",
    "model = Model(input_layer, layer)\n",
    "\n",
    "# compile the model\n",
    "opt = Adam(learning_rate = 3e-3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "#print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        accuracy = logs[\"val_accuracy\"]\n",
    "        if accuracy >= self.threshold:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "batch_size=32\n",
    "no_epochs= 48\n",
    "# Fit data to model\n",
    "history = model.fit(X_train,  y_train_OH,\n",
    "          batch_size=batch_size,\n",
    "          epochs=no_epochs,\n",
    "          verbose=True,\n",
    "        validation_data=(X_test, y_test_OH), callbacks=[MyThresholdCallback(threshold=0.6)])\n",
    "\n",
    "# Generate generalization metrics\n",
    "scores = model.evaluate(X_test, y_test_OH, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_test[0].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#plot accuracy\\\n",
    "plt.plot(history.history['accuracy'], label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val')\n",
    "plt.plot(np.ones(len(history.history['accuracy']))*0.2, '--', label = 'chance')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Train/val accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlim(0,no_epochs-1)\n",
    "plt.xticks(np.arange(0,no_epochs, 2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model:\n",
    "    model.save(\"CNN_60.h5\", save_format = 'h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ntpath' from 'C:\\\\Users\\\\rjpbe\\\\Anaconda3\\\\envs\\\\neuromorphic\\\\lib\\\\ntpath.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuromorphic] *",
   "language": "python",
   "name": "conda-env-neuromorphic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
